{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to rediscover the Z boson yourself!\n",
    "This notebook uses ATLAS Open Data http://opendata.atlas.cern to show you the steps to rediscover the Z boson yourself!\n",
    "\n",
    "The idea is that you add extra cuts to increase the ratio of signal ($Z \\rightarrow e^{+}e^{-}$ and $Z \\rightarrow \\mu^{+}\\mu^{-}$) to background ($Z \\rightarrow \\tau^{+}\\tau^{-}$, $W$, single top, $t\\bar{t}$, dibosons, low-mass Drell-Yan)\n",
    "\n",
    "The datasets used in this notebook have already been filtered to include exactly 2 leptons per event, so that processing is quicker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"Z_feynman.pdf\" style=\"width:40%\"></CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First time setup on your computer\n",
    "This first cell only needs to be run the first time you open this notebook on your computer. \n",
    "\n",
    "If you close Jupyter and re-open on the same computer, you won't need to run this first cell again.\n",
    "\n",
    "If you open on binder, you don't need to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade --user pip\n",
    "!{sys.executable} -m pip install -U numpy pandas uproot matplotlib --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To setup everytime\n",
    "Cell -> Run All Below\n",
    "\n",
    "to be done every time you re-open this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches # for \"Total SM & uncertainty\" merged legend handle\n",
    "from matplotlib.lines import Line2D # for dashed line in legend\n",
    "from matplotlib.ticker import AutoMinorLocator,LogLocator,LogFormatterSciNotation # for minor ticks\n",
    "import scipy.stats\n",
    "\n",
    "import infofile\n",
    "import labelfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumi = 1000\n",
    "\n",
    "fraction = 0.001 # reduce this is you want the code to run quicker\n",
    "                                                                                                                                  \n",
    "tuple_path = \"Input/\" # local\n",
    "#tuple_path = \"http://opendata.atlas.cern/release/samples/\" # web address\n",
    "\n",
    "stack_order = ['W','single top',r'$t\\bar{t}$','Diboson','Drell Yan','Z'] # put smallest contribution first, then increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "\n",
    "    'data': {\n",
    "        'list' : ['DataEgamma','DataMuons']\n",
    "    },\n",
    "\n",
    "    'W' : {\n",
    "        'list' : ['WenuNoJetsBVeto','WenuJetsBVeto','WenuWithB','WmunuNoJetsBVeto','WmunuJetsBVeto','WmunuWithB','WtaunuNoJetsBVeto','WtaunuJetsBVeto','WtaunuWithB'],\n",
    "        'color' : \"#e55934\"\n",
    "    },\n",
    "\n",
    "    'Z' : {\n",
    "        'list' : ['Zee','Zmumu','Ztautau'],\n",
    "        'color' : \"#086788\"\n",
    "    },\n",
    "   \n",
    "    r'$t\\bar{t}$' : {\n",
    "        'list' : ['ttbar_lep','ttbar_had'],\n",
    "        'color' : \"#9bc53d\"\n",
    "    },\n",
    "\n",
    "    'single top' : {\n",
    "        'list' : ['stop_schan','stop_tchan_top','stop_tchan_antitop','stop_wtchan'],\n",
    "        'color' : \"#fde74c\"\n",
    "    },\n",
    "    \n",
    "    'Drell Yan' : {\n",
    "        'list' : ['DYeeM08to15', 'DYeeM15to40', 'DYmumuM08to15', 'DYmumuM15to40', 'DYtautauM08to15', 'DYtautauM15to40'],\n",
    "        'color' : \"#5bc0eb\"\n",
    "    },\n",
    "\n",
    "    'Diboson' : {\n",
    "        'list' : ['WW','WZ','ZZ'],\n",
    "        'color' : \"#fa7921\"\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sample(s):\n",
    "    print('Processing '+s+' samples')\n",
    "    frames = []\n",
    "    for val in samples[s]['list']:\n",
    "        prefix = \"MC/exactly2lep.mc_\"\n",
    "        if s == 'data':\n",
    "            prefix = \"Data/exactly2lep.\"\n",
    "        else: prefix += str(infofile.infos[val][\"DSID\"])+\".\"\n",
    "        fileString = tuple_path+prefix+val+\".root\" \n",
    "        if fileString != \"\":\n",
    "            temp = read_file(fileString,val)\n",
    "            frames.append(temp)\n",
    "        else:\n",
    "            print(\"Error: \"+val+\" not found!\")\n",
    "    data_s = pd.concat(frames)\n",
    "    return data_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    data = {}\n",
    "    for s in samples:\n",
    "        data[s] = read_sample(s)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weight(mcWeight,scaleFactor_PILEUP,scaleFactor_ELE,\n",
    "                scaleFactor_MUON, scaleFactor_TRIGGER):\n",
    "    return mcWeight*scaleFactor_PILEUP*scaleFactor_ELE*scaleFactor_MUON*scaleFactor_TRIGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xsec_weight(totalWeight,sample):\n",
    "    info = infofile.infos[sample]\n",
    "    weight = (lumi*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"])\n",
    "    weight *= totalWeight\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mll(lep_pts,lep_etas,lep_phis):\n",
    "    mll = 2*lep_pts[0]*lep_pts[1]\n",
    "    cosh = math.cosh(lep_etas[0]-lep_etas[1])\n",
    "    cos = math.cos(lep_phis[0]-lep_phis[1])\n",
    "    mll *= ( cosh - cos )\n",
    "    return math.sqrt(mll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing an already uncommented cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you change a cut: Cell -> Run All Below\n",
    "\n",
    "If you uncomment a cut here, you also need to uncomment the corresponding cut in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut on number of leptons\n",
    "def cut_n_lep(lep_n):\n",
    "    # return when number of leptons is not equal to 2\n",
    "    # exclamation mark (!) means \"not\"\n",
    "    # so != means \"not equal to\"\n",
    "    return lep_n != 2\n",
    "\n",
    "# cut on lepton charge\n",
    "def cut_lep_charge(lep_charge):\n",
    "    # return when sum of lepton charges is not equal to 0\n",
    "    # first lepton is [0], 2nd lepton is [1]\n",
    "    return lep_charge[0] + lep_charge[1] != 0\n",
    "\n",
    "# cut on lepton type\n",
    "def cut_lep_type(lep_type):\n",
    "# for an electron lep_type is 11\n",
    "# for a muon lep_type is 13\n",
    "    return lep_type[0]!=lep_type[1]\n",
    "\n",
    "# cut on lepton pt\n",
    "def cut_lep_pt(lep_pt):\n",
    "# want to throw away events where the leptons have lep_pt[] < 25000 MeV \n",
    "    return (lep_pt[0] < 25000) or (lep_pt[1] < 25000)\n",
    "\n",
    "# cut on invariant mass of Z boson candidate \n",
    "def cut_mll(mll):\n",
    "# want invariant mass of same-type-opposite-charge lepton pair to be in range 71 < m < 111 GeV\n",
    "    return (mll < 71.12*1000) or (mll > 111.12*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncommenting a new cut\n",
    "If you add a cut: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time()\n",
    "    print(\"\\tProcessing: \"+sample)\n",
    "    data_all = pd.DataFrame()\n",
    "    mc = uproot.open(path)[\"mini\"]\n",
    "    numevents = uproot.numentries(path, \"mini\")\n",
    "    for data in mc.iterate([\"lep_n\",\"lep_pt\",\"lep_eta\",\"lep_phi\",\"lep_charge\",\"lep_type\", # add more variables here if you make cuts on them\n",
    "                         \"mcWeight\",\"scaleFactor_PILEUP\",\"scaleFactor_ELE\",\"scaleFactor_MUON\", \n",
    "                         \"scaleFactor_TRIGGER\"], flatten=False, entrysteps=2500000, outputtype=pd.DataFrame, entrystop=numevents*fraction):\n",
    "\n",
    "        nIn = len(data.index)\n",
    "\n",
    "        if 'Data' not in sample:\n",
    "            data['totalWeight'] = np.vectorize(calc_weight)(data.mcWeight,data.scaleFactor_PILEUP,data.scaleFactor_ELE,data.scaleFactor_MUON,data.scaleFactor_TRIGGER)\n",
    "            data['totalWeight'] = np.vectorize(get_xsec_weight)(data.totalWeight,sample)\n",
    "\n",
    "        data.drop([\"mcWeight\",\"scaleFactor_PILEUP\",\"scaleFactor_ELE\",\"scaleFactor_MUON\",\"scaleFactor_TRIGGER\"], axis=1, inplace=True)\n",
    "\n",
    "        # cut on number of leptons\n",
    "        fail = data[ np.vectorize(cut_n_lep)(data.lep_n) ].index\n",
    "        data.drop(fail, inplace=True)\n",
    "\n",
    "        # dataframe contents can be printed at any stage like this\n",
    "        #print(data)\n",
    "\n",
    "        # dataframe column can be printed at any stage like this\n",
    "        #print(data['lep_charge'])\n",
    "\n",
    "        # dataframe columns can be printed at any stage like this\n",
    "        #print(data[['lep_charge','lep_type']])\n",
    "\n",
    "        # cut on lepton charge\n",
    "        #fail = data[ np.vectorize(cut_lep_charge)(data.lep_charge) ].index\n",
    "        #data.drop(fail, inplace=True)\n",
    "\n",
    "        # cut on lepton type\n",
    "        #fail = data[ np.vectorize(cut_lep_type)(data.lep_type) ].index\n",
    "        #data.drop(fail, inplace=True)\n",
    "\n",
    "        # cut on lepton pt\n",
    "        #fail = data[ np.vectorize(cut_lep_pt)(data.lep_pt) ].index\n",
    "        #data.drop(fail, inplace=True)\n",
    "\n",
    "        # calculation of 2-lepton invariant mass\n",
    "        data['mll'] = np.vectorize(calc_mll)(data.lep_pt,data.lep_eta,data.lep_phi)\n",
    "\n",
    "        # cut on mll\n",
    "        #fail = data[ np.vectorize(cut_mll)(data.mll) ].index\n",
    "        #data.drop(fail, inplace=True)\n",
    "\n",
    "        nOut = len(data.index)\n",
    "        data_all = data_all.append(data)\n",
    "        elapsed = time.time() - start\n",
    "        print(\"\\t\\tTime taken: \"+str(elapsed)+\", nIn: \"+str(nIn)+\", nOut: \"+str(nOut))\n",
    "\n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data = get_data_from_files()\n",
    "#for i in data: \n",
    "#   data[i].to_csv('dataframe_id_'+str(i)+'.csv')\n",
    "elapsed = time.time() - start\n",
    "print(\"Time taken: \"+str(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a change to plotting\n",
    "If you only want a make a change in the plot: Cell -> Run All Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):\n",
    "\n",
    "    # change plotting parameters\n",
    "    bin_width = 5\n",
    "    num_bins = 24\n",
    "    xrange_min = 0\n",
    "    x_variable = 'mll'\n",
    "    log_y = False\n",
    "    signal_format = None # 'line' or 'hist' or None\n",
    "    Total_SM_label = False # for Total SM black line in plot and legend\n",
    "    plot_label = r'$Z \\rightarrow \\ell^+\\ell^-$'\n",
    "    signal_label = ''\n",
    "    \n",
    "    # change aesthetic parameters if you want\n",
    "    y_label_x_position = -0.09 # 0.09 to the left of y axis\n",
    "    legend_loc = (0.3,0.1)\n",
    "    log_top_margin = 10000 # to decrease the separation between data and the top of the figure, remove a 0\n",
    "    linear_top_margin = 1.1 # to decrease the separation between data and the top of the figure, pick a decimal closer to 1\n",
    "\n",
    "    \n",
    "    # *******************\n",
    "    # general definitions (shouldn't need to change)\n",
    "    lumi_used = str(lumi*fraction/1000)    \n",
    "    signal = None\n",
    "    for s in samples.keys():\n",
    "        if s not in stack_order and s!='data': signal = s\n",
    "    \n",
    "    bins = [xrange_min + x*bin_width for x in range(num_bins+1) ]\n",
    "    bin_centres = [xrange_min+bin_width/2 + x*bin_width for x in range(num_bins) ]\n",
    "\n",
    "    data_x,_ = np.histogram(data['data'][x_variable].values/1000, bins=bins)\n",
    "    data_x_errors = np.sqrt(data_x)\n",
    "\n",
    "    signal_x = None\n",
    "    if signal_format=='line':\n",
    "        signal_x,_ = np.histogram(data[signal][x_variable].values/1000,bins=bins,weights=data[signal].totalWeight.values)\n",
    "    elif signal_format=='hist':\n",
    "        signal_x = data[signal][x_variable].values/1000\n",
    "        signal_weights = data[signal].totalWeight.values\n",
    "        signal_color = samples[signal]['color']\n",
    "    \n",
    "    mc_x = []\n",
    "    mc_weights = []\n",
    "    mc_colors = []\n",
    "    mc_labels = []\n",
    "    mc_x_tot = np.zeros(len(bin_centres))\n",
    "\n",
    "    for s in stack_order:\n",
    "        mc_labels.append(s)\n",
    "        mc_x.append(data[s][x_variable].values/1000)\n",
    "        mc_colors.append(samples[s]['color'])\n",
    "        mc_weights.append(data[s].totalWeight.values)\n",
    "        mc_x_heights,_ = np.histogram(data[s][x_variable].values/1000,bins=bins,weights=data[s].totalWeight.values)\n",
    "        mc_x_tot = np.add(mc_x_tot, mc_x_heights)\n",
    "    \n",
    "    mc_x_err = np.sqrt(mc_x_tot)\n",
    "    \n",
    "    \n",
    "    # *************\n",
    "    # Main plot \n",
    "    # *************\n",
    "    plt.axes([0.1,0.3,0.85,0.65]) #(left, bottom, width, height)\n",
    "    main_axes = plt.gca()\n",
    "    main_axes.errorbar( x=bin_centres, y=data_x, yerr=data_x_errors, fmt='ko', label='Data')\n",
    "    mc_heights = main_axes.hist(mc_x,bins=bins,weights=mc_weights,stacked=True,color=mc_colors, label=mc_labels)\n",
    "    if Total_SM_label:\n",
    "        totalSM_handle, = main_axes.step(bins,np.insert(mc_x_tot,0,mc_x_tot[0]),color='black')\n",
    "    if signal_format=='line':\n",
    "        main_axes.step(bins,np.insert(signal_x,0,signal_x[0]),color=samples[signal]['color'], linestyle='--',\n",
    "                       label=signal)\n",
    "    elif signal_format=='hist':\n",
    "        main_axes.hist(signal_x,bins=bins,bottom=mc_x_tot,weights=signal_weights,color=signal_color,label=signal)\n",
    "    main_axes.bar(bin_centres,2*mc_x_err,bottom=mc_x_tot-mc_x_err,alpha=0.5,color='none',hatch=\"////\",\n",
    "                  width=bin_width, label='Stat. Unc.')\n",
    "        \n",
    "    main_axes.set_xlim(left=xrange_min,right=bins[-1])\n",
    "    main_axes.xaxis.set_minor_locator(AutoMinorLocator()) # separation of x axis minor ticks\n",
    "    main_axes.tick_params(which='both',direction='in',top=True,labeltop=False,labelbottom=False,right=True,labelright=False)\n",
    "    main_axes.set_ylabel(r'Events / '+str(bin_width)+r' GeV',fontname='sans-serif',horizontalalignment='right',y=1.0,fontsize=11)\n",
    "    if log_y:\n",
    "        main_axes.set_yscale('log')\n",
    "        smallest_contribution = mc_heights[0][0]\n",
    "        smallest_contribution.sort()\n",
    "        bottom = smallest_contribution[-2]\n",
    "        top = np.amax(data_x)*log_top_margin\n",
    "        main_axes.set_ylim(bottom=bottom,top=top)\n",
    "        main_axes.yaxis.set_major_formatter(CustomTicker())\n",
    "        locmin = LogLocator(base=10.0,subs=(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9),numticks=12)\n",
    "        main_axes.yaxis.set_minor_locator(locmin)\n",
    "    else: \n",
    "        main_axes.set_ylim(bottom=0,top=(np.amax(data_x)+math.sqrt(np.amax(data_x)))*linear_top_margin)\n",
    "        main_axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        \n",
    "    plt.text(0.05,0.97,'ATLAS',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes,style='italic',weight='bold',fontsize=13)\n",
    "    plt.text(0.19,0.97,'Open Data',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes,fontsize=13)\n",
    "    plt.text(0.05,0.9,'for education only',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes,style='italic',fontsize=8)\n",
    "    plt.text(0.05,0.86,r'$\\sqrt{s}=13\\,\\mathrm{TeV},\\;\\int L\\,dt=$'+lumi_used+'$\\,\\mathrm{fb}^{-1}$',ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes)\n",
    "    plt.text(0.05,0.78,plot_label,ha=\"left\",va=\"top\",family='sans-serif',transform=main_axes.transAxes)\n",
    "    \n",
    "    # Create new legend handles but use the colors from the existing ones \n",
    "    handles, labels = main_axes.get_legend_handles_labels()\n",
    "    if signal_format=='line':\n",
    "        handles[labels.index(signal)] = Line2D([], [], c=samples[signal]['color'], linestyle='dashed')\n",
    "    if Total_SM_label:\n",
    "        uncertainty_handle = mpatches.Patch(facecolor='none',hatch='////')\n",
    "        handles.append((totalSM_handle,uncertainty_handle))\n",
    "        labels.append('Total SM')\n",
    "    \n",
    "    # specify order within legend\n",
    "    new_handles = [handles[labels.index('Data')]]\n",
    "    new_labels = ['Data']\n",
    "    for s in reversed(stack_order):\n",
    "        new_handles.append(handles[labels.index(s)])\n",
    "        new_labels.append(s)\n",
    "    if Total_SM_label:\n",
    "        new_handles.append(handles[labels.index('Total SM')])\n",
    "        new_labels.append('Total SM')\n",
    "    else: \n",
    "        new_handles.append(handles[labels.index('Stat. Unc.')])\n",
    "        new_labels.append('Stat. Unc.')\n",
    "    if signal is not None:\n",
    "        new_handles.append(handles[labels.index(signal)])\n",
    "        new_labels.append(signal_label)\n",
    "    main_axes.legend(handles=new_handles, labels=new_labels, frameon=False, loc=legend_loc)\n",
    "    \n",
    "    \n",
    "    # *************\n",
    "    # Data/MC ratio \n",
    "    # *************\n",
    "    plt.axes([0.1,0.1,0.85,0.2]) #(left, bottom, width, height)\n",
    "    ratio_axes = plt.gca()\n",
    "    ratio_axes.errorbar( x=bin_centres, y=data_x/mc_x_tot, yerr=data_x_errors/mc_x_tot, fmt='ko')\n",
    "    ratio_axes.bar(bin_centres,2*mc_x_err/mc_x_tot,bottom=1-mc_x_err/mc_x_tot,alpha=0.5,color='none',\n",
    "            hatch=\"////\",width=bin_width)\n",
    "    ratio_axes.plot(bins,np.ones(len(bins)),color='k')\n",
    "    ratio_axes.set_xlim(left=xrange_min,right=bins[-1])\n",
    "    ratio_axes.xaxis.set_minor_locator(AutoMinorLocator()) # separation of x axis minor ticks\n",
    "    ratio_axes.xaxis.set_label_coords(0.9,-0.2) # (x,y) of x axis label # 0.2 down from x axis\n",
    "    ratio_axes.set_xlabel(labelfile.variable_labels[x_variable],fontname='sans-serif',fontsize=11)\n",
    "    ratio_axes.tick_params(which='both',direction='in',top=True,labeltop=False,right=True,labelright=False)\n",
    "    ratio_axes.set_ylim(bottom=0,top=2.5)\n",
    "    ratio_axes.set_yticks([0,1,2])\n",
    "    ratio_axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    if signal is not None:\n",
    "        ratio_axes.set_ylabel(r'Data/SM',fontname='sans-serif',x=1,fontsize=11)\n",
    "    else:\n",
    "        ratio_axes.set_ylabel(r'Data/MC',fontname='sans-serif',fontsize=11)\n",
    "        \n",
    "        \n",
    "    # Generic features for both plots\n",
    "    main_axes.yaxis.set_label_coords(y_label_x_position,1)\n",
    "    ratio_axes.yaxis.set_label_coords(y_label_x_position,0.5)\n",
    "    \n",
    "    plt.savefig(\"plot.pdf\")\n",
    "    \n",
    "    return signal_x,mc_x_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_yields,background_yields = plot_data(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
